// Configuration de la radio
const radioConfig = {
    streamUrl: '' // URL du stream radio (charg√©e depuis Firebase)
};

// Chemins Firebase pour la radio
const FIREBASE_RADIO_STATUS_PATH = 'radio/status';

// √âl√©ments DOM
const audioPlayer = document.getElementById('audioPlayer');
const playPauseBtn = document.getElementById('playPauseBtn');
const trackTitle = document.getElementById('trackTitle');
const currentTimeEl = document.getElementById('currentTime');
const vinylRecord = document.querySelector('.vinyl-record');
const playIcon = document.querySelector('.play-icon');
const pauseIcon = document.querySelector('.pause-icon');

// √âtat du lecteur
let isPlaying = false;

// Mise √† jour de l'heure
function updateTime() {
    const now = new Date();
    const hours = String(now.getHours()).padStart(2, '0');
    const minutes = String(now.getMinutes()).padStart(2, '0');
    currentTimeEl.textContent = `${hours}:${minutes}`;
}

// Mise √† jour du titre de la piste
function updateTrackTitle() {
    trackTitle.textContent = 'EN DIRECT';
}

// Fonction play/pause
function togglePlayPause() {
    if (isPlaying) {
        // Pause
        if (streamUrl && audioPlayer.src) {
            // Si on utilise un stream URL, utiliser l'√©l√©ment audio
            audioPlayer.pause();
        } else {
            // Sinon, arr√™ter le streaming vocal
            stopListeningToAudio();
        }
        isPlaying = false;
        isPlayingAudio = false;
        if (playIcon) playIcon.style.display = 'block';
        if (pauseIcon) pauseIcon.style.display = 'none';
        if (vinylRecord) vinylRecord.classList.remove('playing');
    } else {
        // Play - Activer le contexte audio puis d√©marrer la lecture
        // Le navigateur n√©cessite une interaction utilisateur pour activer l'audio
        if (!audioContextListener || audioContextListener.state === 'closed') {
            audioContextListener = new (window.AudioContext || window.webkitAudioContext)({
                sampleRate: 48000,
                latencyHint: 'interactive'
            });
        }
        
        // TOUJOURS essayer de reprendre le contexte (d√©blocage utilisateur)
        if (audioContextListener.state === 'suspended') {
            audioContextListener.resume().then(() => {
                console.log('‚úÖ Contexte audio activ√© par interaction utilisateur');
                startListeningToAudio();
                // Activer l'interface
                isPlaying = true;
                if (playIcon) playIcon.style.display = 'none';
                if (pauseIcon) pauseIcon.style.display = 'block';
                if (vinylRecord) vinylRecord.classList.add('playing');
            }).catch(err => {
                console.error('‚ùå Erreur activation audio:', err);
                alert('Erreur: Impossible d\'activer l\'audio. V√©rifiez les permissions.');
            });
        } else {
            startListeningToAudio();
            // Activer l'interface
            isPlaying = true;
            if (playIcon) playIcon.style.display = 'none';
            if (pauseIcon) pauseIcon.style.display = 'block';
            if (vinylRecord) vinylRecord.classList.add('playing');
        }
    }
}

// Simulation de la lecture (si pas de stream)
function simulatePlayback() {
    isPlaying = true;
    playIcon.style.display = 'none';
    pauseIcon.style.display = 'block';
    vinylRecord.classList.add('playing');
}

// Gestion des erreurs audio
audioPlayer.addEventListener('error', (e) => {
    console.error('‚ùå Erreur audio player:', e, audioPlayer.error);
    
    // Si c'est une erreur de fichier local ou source non support√©e, basculer vers streaming vocal
    if (audioPlayer.error && (
        audioPlayer.error.code === MediaError.MEDIA_ERR_SRC_NOT_SUPPORTED ||
        (streamUrl && (streamUrl.startsWith('file://') || streamUrl.match(/^[A-Z]:[\\/]/)))
    )) {
        console.warn('‚ö†Ô∏è Source non support√©e, basculement vers streaming vocal Firebase');
        streamUrl = '';
        audioPlayer.src = '';
        
        // V√©rifier si une diffusion vocale est en cours
        if (typeof firebase !== 'undefined' && firebase.apps.length > 0) {
            database.ref(FIREBASE_RADIO_STATUS_PATH).once('value', (snapshot) => {
                const status = snapshot.val();
                if (status && status.isLive === true) {
                    console.log('‚úÖ Diffusion vocale d√©tect√©e, d√©marrage...');
                    autoStartAudio();
                } else {
                    updateAudioStatus(false, 'Aucune source disponible');
                }
            });
        }
    } else if (isPlaying) {
        // Autres erreurs, essayer le mode simulation
        simulatePlayback();
    }
});

// Bouton play/pause
playPauseBtn.addEventListener('click', togglePlayPause);


// ============================================
// RADIO STREAM - Diffusion vocale directe
// ============================================

let audioChunksQueue = [];
let isPlayingAudio = false;
let lastChunkTimestamp = 0;
let audioContextListener = null;
let audioSource = null;
let silentAudioSource = null; // Source audio silencieuse pour maintenir l'ic√¥ne dans l'onglet
let chunksReceivedCount = 0;
let lastReceivedTime = null;
let gainNode = null; // Pour contr√¥ler le volume
let currentVolume = 1.0; // Volume par d√©faut √† 100%

// Charger et jouer les chunks audio depuis Firebase
function loadRadioStream() {
    if (typeof firebase === 'undefined' || !firebase.apps.length) {
        setTimeout(loadRadioStream, 1000);
        return;
    }
    
    try {
        // Charger l'URL du stream depuis Firebase
        database.ref('radio/streamUrl').on('value', (snapshot) => {
            const url = snapshot.val();
            if (url && url.trim() !== '') {
                const trimmedUrl = url.trim();
                
                // VALIDATION : Rejeter les fichiers locaux (file://) et les chemins Windows
                if (trimmedUrl.startsWith('file://') || 
                    trimmedUrl.startsWith('C:/') || 
                    trimmedUrl.startsWith('C:\\') ||
                    trimmedUrl.match(/^[A-Z]:[\\/]/)) {
                    console.warn('‚ö†Ô∏è URL de fichier local d√©tect√©e, ignor√©e (s√©curit√© navigateur):', trimmedUrl);
                    console.log('üì° Utilisation du streaming vocal Firebase √† la place');
                    streamUrl = '';
                    // S'assurer qu'on utilise le streaming vocal
                    if (isPlayingAudio) {
                        stopListeningToAudio();
                        const statusRef = database.ref(FIREBASE_RADIO_STATUS_PATH);
                        statusRef.once('value', (statusSnapshot) => {
                            const status = statusSnapshot.val();
                            if (status && status.isLive === true) {
                                autoStartAudio();
                            }
                        });
                    }
                    return;
                }
                
                // Valider que c'est une URL HTTP/HTTPS valide
                try {
                    const urlObj = new URL(trimmedUrl);
                    if (urlObj.protocol !== 'http:' && urlObj.protocol !== 'https:') {
                        console.warn('‚ö†Ô∏è Protocole non support√©:', urlObj.protocol);
                        streamUrl = '';
                        return;
                    }
                } catch (e) {
                    console.warn('‚ö†Ô∏è URL invalide:', trimmedUrl);
                    streamUrl = '';
                    return;
                }
                
                streamUrl = trimmedUrl;
                console.log('üì° URL stream valide charg√©e:', streamUrl);
                // Si on est d√©j√† en lecture, mettre √† jour l'URL
                if (isPlayingAudio) {
                    audioPlayer.src = streamUrl;
                    audioPlayer.play().catch(err => {
                        console.error('‚ùå Erreur lecture stream:', err);
                        // En cas d'erreur, basculer vers le streaming vocal
                        streamUrl = '';
                        updateAudioStatus(false, 'Erreur stream, basculement vocal...');
                    });
                }
            } else {
                streamUrl = '';
                console.log('üì° Pas d\'URL stream, utilisation du streaming vocal');
            }
        });
        
        // √âcouter le statut (en direct/hors ligne) - seulement si pas d'URL stream
        const statusRef = database.ref(FIREBASE_RADIO_STATUS_PATH);
        
        statusRef.on('value', (snapshot) => {
            const status = snapshot.val();
            // Si on a une URL stream, ignorer le statut vocal
            if (streamUrl && streamUrl.trim() !== '') {
                return;
            }
            
            console.log('üì° Statut radio vocal re√ßu:', status);
            if (status && status.isLive === true) {
                if (trackTitle) trackTitle.textContent = 'EN DIRECT üéôÔ∏è';
                console.log('‚úÖ Statut: EN DIRECT - D√©marrage automatique de l\'√©coute');
                
                // D√©marrer automatiquement l'√©coute si pas d√©j√† en cours
                if (!isPlayingAudio) {
                    // Activer automatiquement l'interface et l'audio
                    autoStartAudio();
                } else {
                    // Si d√©j√† en cours, s'assurer que l'interface est √† jour
                    isPlaying = true;
                    isPlayingAudio = true;
                    if (playIcon) playIcon.style.display = 'none';
                    if (pauseIcon) pauseIcon.style.display = 'block';
                    if (vinylRecord) vinylRecord.classList.add('playing');
                    if (trackTitle) trackTitle.textContent = 'EN DIRECT üéôÔ∏è';
                    updateAudioStatus(true, 'Diffusion en cours');
                }
            } else {
                if (trackTitle) trackTitle.textContent = 'EN DIRECT';
                console.log('‚è∏Ô∏è Statut: Hors ligne');
                stopListeningToAudio();
                // Mettre √† jour l'interface
                isPlaying = false;
                isPlayingAudio = false;
                if (playIcon) playIcon.style.display = 'block';
                if (pauseIcon) pauseIcon.style.display = 'none';
                if (vinylRecord) vinylRecord.classList.remove('playing');
            }
        });
        
        // V√©rifier imm√©diatement si une diffusion est en cours
        statusRef.once('value', (snapshot) => {
            const status = snapshot.val();
            // Si on a une URL stream, ne pas v√©rifier le statut vocal
            if (streamUrl && streamUrl.trim() !== '') {
                return;
            }
            
            console.log('üì° V√©rification statut initial:', status);
            if (status && status.isLive === true) {
                trackTitle.textContent = 'EN DIRECT üéôÔ∏è';
                console.log('‚úÖ Diffusion d√©j√† en cours - D√©marrage automatique imm√©diat');
                if (!isPlayingAudio) {
                    // D√©marrer automatiquement l'audio
                    autoStartAudio();
                } else {
                    // Si d√©j√† en cours, activer l'interface
                    isPlaying = true;
                    playIcon.style.display = 'none';
                    pauseIcon.style.display = 'block';
                    vinylRecord.classList.add('playing');
                }
            } else {
                trackTitle.textContent = 'EN DIRECT';
                console.log('‚è∏Ô∏è Aucune diffusion en cours');
            }
        });
        
        // Enregistrer comme auditeur
        const listenerId = 'listener_' + Date.now() + '_' + Math.random().toString(36).substr(2, 9);
        database.ref(`radio/listeners/${listenerId}`).set({
            joinedAt: new Date().toISOString(),
            lastSeen: new Date().toISOString()
        });
        
        // Mettre √† jour lastSeen toutes les 30 secondes
        setInterval(() => {
            database.ref(`radio/listeners/${listenerId}`).update({
                lastSeen: new Date().toISOString()
            });
        }, 30000);
        
        // Nettoyer √† la fermeture
        window.addEventListener('beforeunload', () => {
            database.ref(`radio/listeners/${listenerId}`).remove();
        });
        
    } catch (error) {
        console.error('‚ùå Erreur chargement stream:', error);
    }
}

// Variable pour le stream URL
let streamUrl = '';

// Variables pour le syst√®me de rediffusion am√©lior√©
let chunksListenerRef = null;
let reconnectAttempts = 0;
let maxReconnectAttempts = 5;
let reconnectDelay = 0; // Pas de d√©lai
let lastSuccessfulChunkTime = null;
let healthCheckInterval = null;
let autoPlayEnabled = true; // Activer la lecture automatique par d√©faut

// D√©tection mobile pour optimisations
const isMobile = /Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent);
const isIOS = /iPhone|iPad|iPod/i.test(navigator.userAgent);
const isAndroid = /Android/i.test(navigator.userAgent);

// D√©marrer automatiquement l'audio (sans interaction utilisateur requise)
function autoStartAudio() {
    console.log('üéµ D√©marrage automatique de l\'audio...');
    
    // Sur mobile, l'autoplay est plus strict - n√©cessite souvent une interaction
    if (isMobile) {
        console.log('üì± D√©tection mobile - autoplay optimis√©');
    }
    
    // Cr√©er le contexte audio s'il n'existe pas - OPTIMIS√â POUR MOBILE
    if (!audioContextListener || audioContextListener.state === 'closed') {
        try {
            // Sur mobile, utiliser 'playback' pour meilleure performance
            const latencyHint = isMobile ? 'playback' : 'interactive';
            audioContextListener = new (window.AudioContext || window.webkitAudioContext)({
                sampleRate: 48000,
                latencyHint: latencyHint // 'playback' sur mobile pour meilleure performance
            });
            console.log(`‚úÖ Contexte audio cr√©√© automatiquement (${isMobile ? 'mobile' : 'desktop'})`);
        } catch (error) {
            console.error('‚ùå Erreur cr√©ation contexte:', error);
            // Si √©chec, essayer avec startListeningToAudio qui demande l'interaction
            startListeningToAudio();
            return;
        }
    }
    
    // Essayer de reprendre le contexte (peut n√©cessiter une interaction utilisateur)
    if (audioContextListener.state === 'suspended') {
        // Essayer plusieurs fois de reprendre le contexte
        const resumeAudio = () => {
            audioContextListener.resume().then(() => {
                console.log('‚úÖ Contexte audio activ√© automatiquement');
                // D√©marrer l'√©coute
                startListeningToAudio();
                // Activer l'interface
                isPlaying = true;
                if (playIcon) playIcon.style.display = 'none';
                if (pauseIcon) pauseIcon.style.display = 'block';
                if (vinylRecord) vinylRecord.classList.add('playing');
            }).catch(err => {
                console.warn('‚ö†Ô∏è Impossible d\'activer automatiquement, nouvelle tentative...', err);
                // R√©essayer apr√®s un court d√©lai
                setTimeout(() => {
                    if (audioContextListener && audioContextListener.state === 'suspended') {
                        resumeAudio();
                    } else if (audioContextListener && audioContextListener.state === 'running') {
                        startListeningToAudio();
                        isPlaying = true;
                        if (playIcon) playIcon.style.display = 'none';
                        if (pauseIcon) pauseIcon.style.display = 'block';
                        if (vinylRecord) vinylRecord.classList.add('playing');
                    } else {
                        updateAudioStatus(false, 'Cliquez sur ‚ñ∂Ô∏è pour d√©marrer');
                    }
                }, 500);
            });
        };
        
        resumeAudio();
    } else {
        // Contexte d√©j√† actif, d√©marrer directement
        startListeningToAudio();
        // Activer l'interface
        isPlaying = true;
        if (playIcon) playIcon.style.display = 'none';
        if (pauseIcon) pauseIcon.style.display = 'block';
        if (vinylRecord) vinylRecord.classList.add('playing');
    }
}

// D√©marrer l'√©coute des chunks audio
function startListeningToAudio() {
    if (isPlayingAudio) {
        console.log('‚ö†Ô∏è √âcoute d√©j√† en cours');
        return;
    }
    
    // Si une URL de stream est configur√©e, utiliser l'√©l√©ment audio classique
    if (streamUrl && streamUrl.trim() !== '') {
        // V√©rifier √† nouveau que ce n'est pas un fichier local
        if (streamUrl.startsWith('file://') || 
            streamUrl.startsWith('C:/') || 
            streamUrl.startsWith('C:\\') ||
            streamUrl.match(/^[A-Z]:[\\/]/)) {
            console.warn('‚ö†Ô∏è Fichier local d√©tect√©, basculement vers streaming vocal');
            streamUrl = '';
            // Continuer avec le streaming vocal
        } else {
            console.log('üì° Utilisation du stream URL:', streamUrl);
            audioPlayer.src = streamUrl;
            audioPlayer.play().then(() => {
                isPlayingAudio = true;
                isPlaying = true;
                playIcon.style.display = 'none';
                pauseIcon.style.display = 'block';
                vinylRecord.classList.add('playing');
                trackTitle.textContent = 'EN DIRECT üéôÔ∏è';
                updateAudioStatus(true, 'Stream actif');
            }).catch(err => {
                console.error('‚ùå Erreur lecture stream:', err);
                updateAudioStatus(false, 'Erreur lecture, basculement vocal...');
                // En cas d'erreur, basculer vers le streaming vocal
                streamUrl = '';
                // Ne pas return, continuer avec le streaming vocal
            });
            
            // Si le stream fonctionne, on return
            if (audioPlayer.src && !audioPlayer.error) {
                return;
            }
        }
    }
    
    // Sinon, utiliser le streaming vocal Firebase
    // Cr√©er le contexte audio s'il n'existe pas - OPTIMIS√â POUR MOBILE
    if (!audioContextListener || audioContextListener.state === 'closed') {
        try {
            // Sur mobile, utiliser 'playback' pour meilleure performance et fluidit√©
            const latencyHint = isMobile ? 'playback' : 'interactive';
            audioContextListener = new (window.AudioContext || window.webkitAudioContext)({
                sampleRate: 48000,
                latencyHint: latencyHint
            });
            console.log(`‚úÖ Contexte audio cr√©√© pour streaming vocal (${isMobile ? 'mobile' : 'desktop'})`);
        } catch (error) {
            console.error('‚ùå Erreur cr√©ation contexte:', error);
            return;
        }
    }
    
    // Reprendre le contexte s'il est suspendu (n√©cessite une interaction utilisateur)
    if (audioContextListener.state === 'suspended') {
        console.log('‚ö†Ô∏è Contexte audio suspendu, tentative de reprise...');
        audioContextListener.resume().then(() => {
            console.log('‚úÖ Contexte audio activ√© avec succ√®s');
        }).catch(err => {
            console.error('‚ùå Erreur activation contexte:', err);
            // Ne pas alerter, juste logger - le syst√®me r√©essayera automatiquement
        });
    } else {
        console.log('‚úÖ Contexte audio d√©j√† actif:', audioContextListener.state);
    }
    
    // S'assurer que le contexte reste actif - v√©rification p√©riodique
    const keepAudioActive = setInterval(() => {
        if (!isPlayingAudio) {
            clearInterval(keepAudioActive);
            return;
        }
        
        if (audioContextListener && audioContextListener.state === 'suspended') {
            console.log('üîÑ R√©activation du contexte audio suspendu...');
            audioContextListener.resume().catch(err => {
                console.warn('‚ö†Ô∏è Impossible de r√©activer:', err);
            });
        }
    }, 2000); // V√©rifier toutes les 2 secondes
    
    // Stocker l'interval pour le nettoyer plus tard
    if (!window.audioActiveIntervals) {
        window.audioActiveIntervals = [];
    }
    window.audioActiveIntervals.push(keepAudioActive);
    
    isPlayingAudio = true;
    audioChunksQueue = [];
    continuousStreamBuffer = []; // R√©initialiser le buffer continu
    isPlayingStream = false;
    lastChunkTimestamp = Date.now() - 5000;
    reconnectAttempts = 0;
    lastSuccessfulChunkTime = Date.now();
    
    console.log('üéß D√©marrage de l\'√©coute de la diffusion vocale Firebase...');
    
    // Cr√©er le gainNode si n√©cessaire
    if (!gainNode && audioContextListener) {
        try {
            gainNode = audioContextListener.createGain();
            gainNode.gain.value = currentVolume;
            gainNode.connect(audioContextListener.destination);
            console.log('‚úÖ GainNode cr√©√© et connect√©, volume:', currentVolume, '(', (currentVolume * 100).toFixed(0) + '%)');
        } catch (error) {
            console.error('‚ùå Erreur cr√©ation gainNode:', error);
            return;
        }
    }
    
    // V√©rifier que le volume n'est pas √† 0
    if (gainNode && gainNode.gain.value === 0) {
        console.warn('‚ö†Ô∏è Volume √† 0, r√©glage √† 100%');
        gainNode.gain.value = 1.0;
        currentVolume = 1.0;
    }
    
    // Cr√©er une source audio silencieuse continue pour maintenir l'ic√¥ne audio dans l'onglet
    // Cela permet au navigateur de d√©tecter que l'audio est actif
    if (audioContextListener && !silentAudioSource && gainNode) {
        try {
            // Cr√©er un buffer silencieux tr√®s court (0.1 seconde)
            const silentBuffer = audioContextListener.createBuffer(1, Math.floor(audioContextListener.sampleRate * 0.1), audioContextListener.sampleRate);
            // Le buffer est d√©j√† rempli de z√©ros (silence)
            
            // Fonction pour cr√©er et jouer une source silencieuse en boucle
            const playSilentLoop = () => {
                if (!isPlayingAudio || !audioContextListener || audioContextListener.state === 'closed') return;
                
                try {
                    const source = audioContextListener.createBufferSource();
                    source.buffer = silentBuffer;
                    source.connect(gainNode);
                    
                    source.onended = () => {
                        // Rejouer en boucle tant que l'audio est actif
                        if (isPlayingAudio && audioContextListener && audioContextListener.state !== 'closed') {
                            playSilentLoop();
                        } else {
                            silentAudioSource = null;
                        }
                    };
                    
                    source.start(0);
                    silentAudioSource = source;
                } catch (error) {
                    console.warn('‚ö†Ô∏è Erreur cr√©ation source silencieuse:', error);
                    silentAudioSource = null;
                }
            };
            
            // D√©marrer la boucle silencieuse
            playSilentLoop();
            console.log('‚úÖ Source audio silencieuse cr√©√©e pour maintenir l\'ic√¥ne dans l\'onglet');
        } catch (error) {
            console.warn('‚ö†Ô∏è Impossible de cr√©er la source silencieuse:', error);
        }
    }
    
    // √âCOUTER TOUS LES NOUVEAUX CHUNKS - SYST√àME AM√âLIOR√â ET FIABLE
    connectToAudioChunks();
    
    // D√©marrer le health check
    startHealthCheck();
    
    chunksReceivedCount = 0;
    
    console.log('‚úÖ √âcoute de la diffusion vocale d√©marr√©e');
    
    // TOUJOURS mettre √† jour l'interface visuelle
    isPlaying = true;
    isPlayingAudio = true;
    if (playIcon) playIcon.style.display = 'none';
    if (pauseIcon) pauseIcon.style.display = 'block';
    if (vinylRecord) vinylRecord.classList.add('playing');
    if (trackTitle) trackTitle.textContent = 'EN DIRECT üéôÔ∏è';
    
    // Afficher l'indicateur audio
    updateAudioStatus(true, 'En attente des chunks...');
    
    // V√©rifier imm√©diatement s'il y a des chunks en attente
    setTimeout(() => {
        if (audioChunksQueue.length > 0 && !isProcessingBuffer) {
            console.log('üì¶ Chunks en attente d√©tect√©s, d√©marrage de la lecture...');
            processAudioQueue();
        }
    }, 100);
}

// ============================================
// SYST√àME DE STREAMING CONTINU (STYLE APPEL)
// ============================================
// Buffer continu pour accumuler et jouer les streams
let continuousStreamBuffer = [];
let isPlayingStream = false;
let streamStartTime = 0;

// Se connecter aux streams audio Firebase (syst√®me continu)
function connectToAudioChunks() {
    console.log('üîÑ Connexion aux streams audio Firebase (syst√®me continu)...');
    
    // D√©sactiver les anciens listeners
    try {
        database.ref('radio/audioChunks').off('child_added');
        database.ref('radio/audioStream').off('child_added');
    } catch (e) {
        console.warn('‚ö†Ô∏è Erreur d√©sactivation anciens listeners:', e);
    }
    
    // √âcouter les nouveaux streams continus
    const streamRef = database.ref('radio/audioStream');
    
    streamRef.on('child_added', (snapshot) => {
        try {
            if (!isPlayingAudio) {
                console.log('‚è∏Ô∏è Stream re√ßu mais √©coute arr√™t√©e');
                return;
            }
            
            const streamData = snapshot.val();
            if (!streamData || !streamData.data) {
                console.warn('‚ö†Ô∏è Stream invalide re√ßu:', streamData);
                return;
            }
            
            const streamTimestamp = streamData.timestamp || parseInt(snapshot.key);
            const age = Date.now() - streamTimestamp;
            
            // Log pour d√©bogage (premiers streams)
            if (chunksReceivedCount < 5) {
                console.log(`üì• Stream re√ßu: timestamp=${streamTimestamp}, √¢ge=${age}ms, samples=${streamData.samples || 'N/A'}, format=${streamData.format || 'N/A'}`);
            }
            
            // Accepter les streams r√©cents (moins de 5 secondes) ou nouveaux
            if (streamTimestamp > lastChunkTimestamp || age < 5000) {
                lastChunkTimestamp = Math.max(lastChunkTimestamp, streamTimestamp);
                lastSuccessfulChunkTime = Date.now();
                reconnectAttempts = 0;
                
                // Traiter le stream continu
                processContinuousStream(streamData);
            } else {
                if (chunksReceivedCount < 5) {
                    console.log(`‚è≠Ô∏è Stream ignor√© (trop ancien): timestamp=${streamTimestamp}, √¢ge=${age}ms`);
                }
            }
        } catch (error) {
            console.error('‚ùå Erreur traitement stream:', error);
        }
    }, (error) => {
        console.error('‚ùå Erreur listener Firebase:', error);
        handleAudioChunksError(error);
    });
    
    // Fallback: √©couter aussi les anciens chunks pour compatibilit√©
    const chunksRef = database.ref('radio/audioChunks');
    chunksRef.on('child_added', (snapshot) => {
        try {
            if (!isPlayingAudio) return;
            
            const chunkData = snapshot.val();
            if (!chunkData || !chunkData.data) return;
            
            const chunkTimestamp = chunkData.timestamp || parseInt(snapshot.key);
            if (chunkTimestamp > lastChunkTimestamp || (Date.now() - chunkTimestamp) < 10000) {
                lastChunkTimestamp = Math.max(lastChunkTimestamp, chunkTimestamp);
                playAudioChunk(chunkData.data, {
                    format: chunkData.format || 'pcm16',
                    sampleRate: chunkData.sampleRate || 48000,
                    bufferSize: chunkData.bufferSize || 4096
                });
            }
        } catch (error) {
            console.error('‚ùå Erreur traitement chunk (fallback):', error);
        }
    });
    
    console.log('‚úÖ Listener Firebase connect√© pour les streams continus');
}

// Traiter un stream continu (accumulation et lecture fluide)
function processContinuousStream(streamData) {
    try {
        if (!streamData.data || !streamData.sampleRate) {
            console.warn('‚ö†Ô∏è Stream incomplet');
            return;
        }
        
        // D√©coder le stream
        const binaryString = atob(streamData.data);
        const bytes = new Uint8Array(binaryString.length);
        for (let i = 0; i < binaryString.length; i++) {
            bytes[i] = binaryString.charCodeAt(i);
        }
        
        if (bytes.length % 2 !== 0) {
            console.warn('‚ö†Ô∏è Taille stream invalide');
            return;
        }
        
        // Convertir en Float32
        const int16Data = new Int16Array(bytes.buffer);
        const float32Data = new Float32Array(int16Data.length);
        for (let i = 0; i < int16Data.length; i++) {
            float32Data[i] = Math.max(-1, Math.min(1, int16Data[i] / 32768.0));
        }
        
        // Ajouter au buffer continu
        for (let i = 0; i < float32Data.length; i++) {
            continuousStreamBuffer.push(float32Data[i]);
        }
        
        chunksReceivedCount++;
        
        // D√©marrer la lecture si pas d√©j√† en cours
        if (!isPlayingStream && continuousStreamBuffer.length > 0) {
            startContinuousPlayback(streamData.sampleRate);
        }
        
        // D√©tecter le format (Opus ou PCM16)
        const format = (streamData.format || '').toLowerCase();
        const isOpus = format.includes('opus') || (streamData.mimeType && streamData.mimeType.includes('opus'));
        const isStereo = streamData.channels === 2 || format.includes('stereo');
        
        // Si Opus, utiliser le traitement Opus d√©di√©
        if (isOpus) {
            processOpusStream(streamData);
            return;
        }
        
        // Log pour d√©bogage (tous les streams au d√©but, puis p√©riodique)
        if (chunksReceivedCount <= 5 || chunksReceivedCount % 10 === 0) {
            const samples = streamData.samples || (int16Data.length / (isStereo ? 2 : 1));
            console.log(`üì° Stream ${chunksReceivedCount}: ${samples} √©chantillons, ${isStereo ? 'ST√âR√âO' : 'MONO'}, buffer: ${continuousStreamBuffer.length}, dur√©e: ${(samples/streamData.sampleRate).toFixed(3)}s, 48kHz`);
        }
        
        // D√©marrer la lecture si pas d√©j√† en cours
        if (!isPlayingStream && continuousStreamBuffer.length > 0) {
            startContinuousPlayback(streamData.sampleRate, isStereo ? 2 : 1);
        }
        
    } catch (error) {
        console.error('‚ùå Erreur traitement stream continu:', error);
    }
}

// Traiter un stream Opus ST√âR√âO (comme Discord)
let opusStreamBlobs = [];
let opusMediaSource = null;
let opusSourceBuffer = null;
let opusAudioElement = null;
let opusBlobUrl = null;

function processOpusStream(streamData) {
    try {
        // D√©coder base64 en ArrayBuffer
        const binaryString = atob(streamData.data);
        const bytes = new Uint8Array(binaryString.length);
        for (let i = 0; i < binaryString.length; i++) {
            bytes[i] = binaryString.charCodeAt(i);
        }
        
        // Cr√©er un blob Opus WebM
        const mimeType = streamData.mimeType || 'audio/webm;codecs=opus';
        const blob = new Blob([bytes], { type: mimeType });
        
        chunksReceivedCount++;
        
        // Utiliser un √©l√©ment audio avec blob URL (m√©thode simple et fiable)
        playOpusBlobStream(blob);
        
        if (chunksReceivedCount <= 5 || chunksReceivedCount % 10 === 0) {
            console.log(`üéµ Stream Opus ST√âR√âO ${chunksReceivedCount}: ${bytes.length} bytes, 48kHz, 2 canaux (comme Discord)`);
        }
        
    } catch (error) {
        console.error('‚ùå Erreur traitement stream Opus:', error);
    }
}

// Jouer un stream Opus via blob URL (m√©thode simple)
function playOpusBlobStream(blob) {
    try {
        // Cr√©er un √©l√©ment audio d√©di√© pour Opus
        if (!opusAudioElement) {
            opusAudioElement = new Audio();
            opusAudioElement.autoplay = true;
            opusAudioElement.volume = (currentVolume || 1.0) * 1.2; // Volume augment√©
            opusAudioElement.addEventListener('ended', () => {
                // Continuer avec le prochain blob si disponible
                if (opusStreamBlobs.length > 0) {
                    const nextBlob = opusStreamBlobs.shift();
                    playOpusBlobStream(nextBlob);
                }
            });
        }
        
        // Cr√©er un blob URL et le jouer
        if (opusBlobUrl) {
            URL.revokeObjectURL(opusBlobUrl);
        }
        
        opusBlobUrl = URL.createObjectURL(blob);
        opusAudioElement.src = opusBlobUrl;
        
        // Jouer si pas d√©j√† en cours
        if (opusAudioElement.paused) {
            opusAudioElement.play().catch(err => {
                console.warn('‚ö†Ô∏è Erreur lecture Opus:', err);
            });
        }
        
    } catch (error) {
        console.error('‚ùå Erreur lecture blob Opus:', error);
    }
}

// Lire le buffer continu de mani√®re fluide (style Discord - ST√âR√âO)
function startContinuousPlayback(sampleRate, channels = 1) {
    if (isPlayingStream || !audioContextListener || continuousStreamBuffer.length === 0) {
        return;
    }
    
    isPlayingStream = true;
    const targetSampleRate = sampleRate || 48000;
    const numChannels = channels || 1; // 1 = mono, 2 = st√©r√©o
    
    // Fonction r√©cursive pour lire le buffer par morceaux
    const playBufferChunk = () => {
        if (!isPlayingAudio || continuousStreamBuffer.length === 0) {
            isPlayingStream = false;
            return;
        }
        
        // Prendre un morceau du buffer - OPTIMIS√â POUR FLUIDIT√â DISCORD
        // Buffers plus petits (30ms) pour latence minimale et fluidit√© maximale
        const chunkSize = Math.floor(targetSampleRate * 0.03); // 30ms (au lieu de 50ms) pour fluidit√©
        const samplesToPlay = Math.min(chunkSize, continuousStreamBuffer.length);
        
        if (samplesToPlay === 0) {
            // Buffer vide, attendre tr√®s peu (5ms au lieu de 10ms) pour r√©activit√©
            setTimeout(playBufferChunk, 5);
            return;
        }
        
        // Extraire les √©chantillons
        const audioChunk = continuousStreamBuffer.splice(0, samplesToPlay);
        
        // Cr√©er l'AudioBuffer
        try {
            if (audioContextListener.state === 'suspended') {
                audioContextListener.resume();
            }
            
            // Cr√©er l'AudioBuffer ST√âR√âO ou MONO
            const audioBuffer = audioContextListener.createBuffer(numChannels, audioChunk.length / numChannels, targetSampleRate);
            
            if (numChannels === 2) {
                // ST√âR√âO : s√©parer les canaux (interleaved: L, R, L, R, ...)
                const leftChannel = audioBuffer.getChannelData(0);
                const rightChannel = audioBuffer.getChannelData(1);
                for (let i = 0; i < audioChunk.length / 2; i++) {
                    leftChannel[i] = audioChunk[i * 2];
                    rightChannel[i] = audioChunk[i * 2 + 1];
                }
            } else {
                // MONO : un seul canal
                audioBuffer.getChannelData(0).set(audioChunk);
            }
            
            // Cr√©er et jouer la source - VOLUME AUGMENT√â POUR SON AUDIBLE
            if (!gainNode) {
                gainNode = audioContextListener.createGain();
                // Volume par d√©faut √† 1.2 (120%) pour son audible m√™me √† faible volume
                gainNode.gain.value = (currentVolume || 1.0) * 1.2;
                gainNode.connect(audioContextListener.destination);
            } else {
                // S'assurer que le volume est toujours √©lev√© pour son audible
                gainNode.gain.value = Math.max((currentVolume || 1.0) * 1.2, 1.0);
            }
            
            const source = audioContextListener.createBufferSource();
            source.buffer = audioBuffer;
            source.connect(gainNode);
            
            const duration = audioBuffer.duration;
            
            source.onended = () => {
                // Continuer avec le prochain morceau imm√©diatement
                playBufferChunk();
            };
            
            source.onerror = (e) => {
                console.error('‚ùå Erreur source:', e);
                isPlayingStream = false;
            };
            
            source.start(0);
            updateAudioStatus(true, `Stream: ${chunksReceivedCount} paquets`);
            
            // Planifier le prochain morceau (AVANT la fin pour continuit√© maximale - style Discord)
            // R√©duire le d√©lai pour fluidit√© maximale
            const nextDelay = Math.max(duration * 1000 - 10, 0); // 10ms avant la fin (au lieu de 5ms)
            setTimeout(() => {
                if (isPlayingAudio && continuousStreamBuffer.length > 0) {
                    playBufferChunk();
                }
            }, nextDelay);
            
        } catch (error) {
            console.error('‚ùå Erreur lecture buffer:', error);
            isPlayingStream = false;
            // R√©essayer apr√®s un court d√©lai
            setTimeout(() => {
                if (isPlayingAudio && continuousStreamBuffer.length > 0) {
                    isPlayingStream = false;
                    startContinuousPlayback(targetSampleRate);
                }
            }, 20);
        }
    };
    
    // D√©marrer la lecture
    playBufferChunk();
}

// G√©rer les erreurs de connexion aux chunks
function handleAudioChunksError(error) {
    console.error('‚ùå Erreur connexion chunks audio:', error);
    reconnectAttempts++;
    
    if (reconnectAttempts < maxReconnectAttempts) {
        console.log(`üîÑ Tentative de reconnexion ${reconnectAttempts}/${maxReconnectAttempts} dans ${reconnectDelay}ms...`);
        updateAudioStatus(false, `Reconnexion... (${reconnectAttempts}/${maxReconnectAttempts})`);
        
        // Reconnexion imm√©diate sans d√©lai
        if (isPlayingAudio) {
            connectToAudioChunks();
        }
    } else {
        console.error('‚ùå √âchec de reconnexion apr√®s', maxReconnectAttempts, 'tentatives');
        updateAudioStatus(false, 'Erreur de connexion');
        alert('‚ö†Ô∏è Impossible de se connecter au stream audio. V√©rifiez votre connexion internet.');
    }
}

// Health check pour d√©tecter les probl√®mes de connexion
function startHealthCheck() {
    if (healthCheckInterval) {
        clearInterval(healthCheckInterval);
    }
    
    healthCheckInterval = setInterval(() => {
        if (!isPlayingAudio) {
            clearInterval(healthCheckInterval);
            healthCheckInterval = null;
            return;
        }
        
        // Si aucun chunk n'a √©t√© re√ßu depuis 10 secondes, essayer de se reconnecter
        if (lastSuccessfulChunkTime && (Date.now() - lastSuccessfulChunkTime > 10000)) {
            console.warn('‚ö†Ô∏è Aucun chunk re√ßu depuis 10 secondes, reconnexion...');
            updateAudioStatus(false, 'Reconnexion...');
            connectToAudioChunks();
        }
    }, 5000); // V√©rifier toutes les 5 secondes
}

// Arr√™ter l'√©coute
function stopListeningToAudio() {
    if (!isPlayingAudio) return;
    
    isPlayingAudio = false;
    audioChunksQueue = [];
    audioBufferQueue = [];
    continuousStreamBuffer = []; // Arr√™ter le buffer continu
    isPlayingStream = false; // Arr√™ter le streaming continu
    isProcessingBuffer = false;
    
    // Arr√™ter le health check
    if (healthCheckInterval) {
        clearInterval(healthCheckInterval);
        healthCheckInterval = null;
    }
    
    // Arr√™ter tous les intervalles de maintien audio
    if (window.audioActiveIntervals) {
        window.audioActiveIntervals.forEach(interval => clearInterval(interval));
        window.audioActiveIntervals = [];
    }
    
    // D√©sactiver le listener Firebase
    if (chunksListenerRef) {
        try {
            chunksListenerRef.off('child_added');
            chunksListenerRef = null;
        } catch (e) {
            console.warn('‚ö†Ô∏è Erreur d√©sactivation listener:', e);
        }
    }
    
    // D√©sactiver tous les listeners Firebase (chunks et streams)
    try {
        database.ref('radio/audioChunks').off();
        database.ref('radio/audioStream').off();
    } catch (e) {
        console.warn('‚ö†Ô∏è Erreur d√©sactivation listeners Firebase:', e);
    }
    
    if (sourceBuffer) {
        try {
            if (sourceBuffer.updating) {
                sourceBuffer.abort();
            }
        } catch (e) {}
        sourceBuffer = null;
    }
    
    if (mediaSource && mediaSource.readyState === 'open') {
        try {
            mediaSource.endOfStream();
        } catch (e) {}
    }
    
    if (mediaSource) {
        try {
            mediaSource = null;
        } catch (e) {}
    }
    
    // Arr√™ter la source audio silencieuse
    if (silentAudioSource) {
        try {
            silentAudioSource.stop();
            silentAudioSource.disconnect();
        } catch (e) {}
        silentAudioSource = null;
    }
    
    if (audioSource) {
        try {
            audioSource.disconnect();
        } catch (e) {}
        audioSource = null;
    }
    
    // Ne pas fermer le contexte audio, juste le suspendre (pour pouvoir le r√©utiliser)
    if (audioContextListener && audioContextListener.state !== 'closed') {
        try {
            if (audioContextListener.state !== 'suspended') {
                audioContextListener.suspend();
            }
        } catch (e) {
            console.warn('‚ö†Ô∏è Erreur suspension contexte audio:', e);
        }
    }
    
    // R√©initialiser les variables de suivi
    reconnectAttempts = 0;
    lastSuccessfulChunkTime = null;
    
    console.log('‚èπÔ∏è √âcoute arr√™t√©e');
}

// Jouer un chunk audio
function playAudioChunk(base64Data, chunkInfo) {
    try {
        if (!isPlayingAudio) {
            // Si l'√©coute est arr√™t√©e, ignorer le chunk
            return;
        }
        
        chunksReceivedCount++;
        lastReceivedTime = new Date();
        
        // Mettre √† jour le statut visuel
        updateAudioStatus(true);
        
        // LIMITER la queue √† 25 chunks maximum pour meilleure qualit√© (augment√© de 20)
        // Protection anti-crash : si trop de chunks, supprimer les plus anciens
        if (audioChunksQueue.length > 25) {
            console.warn(`‚ö†Ô∏è Queue trop longue (${audioChunksQueue.length}), suppression des anciens chunks`);
            // Supprimer les 12 plus anciens pour garder la queue fluide
            audioChunksQueue.splice(0, 12);
        }
        
        // Ajouter √† la queue avec les informations du chunk
        audioChunksQueue.push({ 
            data: base64Data, 
            format: chunkInfo.format || 'pcm16',
            sampleRate: chunkInfo.sampleRate || 44100,
            bufferSize: chunkInfo.bufferSize || 4096,
            mimeType: chunkInfo.mimeType || null,
            timestamp: Date.now() // Ajouter un timestamp pour le suivi
        });
        
        // Si c'est le premier chunk ou si aucun traitement n'est en cours, d√©marrer la lecture
        if ((audioChunksQueue.length === 1 || !isProcessingBuffer) && isPlayingAudio) {
            processAudioQueue();
        }
        
        // Log seulement tous les 20 chunks pour √©viter le spam
        if (chunksReceivedCount % 20 === 0) {
            console.log(`üéµ ${chunksReceivedCount} chunks re√ßus, queue: ${audioChunksQueue.length}, format: ${chunkInfo.format || 'pcm16'}`);
        }
        
    } catch (error) {
        console.error('‚ùå Erreur traitement chunk audio:', error);
        updateAudioStatus(false, 'Erreur traitement');
    }
}

// Mettre √† jour le statut audio visuel
function updateAudioStatus(isReceiving, message = null) {
    const audioStatus = document.getElementById('audioStatus');
    const statusDot = document.getElementById('statusDot');
    const audioStatusText = document.getElementById('audioStatusText');
    
    if (!audioStatus || !statusDot || !audioStatusText) return;
    
    audioStatus.style.display = 'flex';
    
    if (isReceiving) {
        statusDot.style.background = '#43b581';
        audioStatusText.textContent = message || `Re√ßu: ${chunksReceivedCount} chunks`;
    } else {
        statusDot.style.background = '#f04747';
        audioStatusText.textContent = message || 'Aucun signal';
    }
}

// Buffer audio continu pour cr√©er un stream
let audioBufferQueue = [];
let isProcessingBuffer = false;
let mediaSource = null;
let sourceBuffer = null;
let mediaSourceReady = false;

// TRAITER LA QUEUE AUDIO - SYST√àME COMPL√àTEMENT RECR√â√â ET SIMPLIFI√â
async function processAudioQueue() {
    // V√©rifications de base
    if (!isPlayingAudio) {
        isProcessingBuffer = false;
        return;
    }
    
    if (audioChunksQueue.length === 0) {
        isProcessingBuffer = false;
        updateAudioStatus(true, 'En attente de chunks...');
        return;
    }
    
    if (isProcessingBuffer) {
        return; // D√©j√† en train de traiter
    }
    
    isProcessingBuffer = true;
    const chunk = audioChunksQueue.shift();
    
    try {
        // S'ASSURER QUE LE CONTEXTE AUDIO EST ACTIF
        if (!audioContextListener || audioContextListener.state === 'closed') {
            console.log('üîÑ Recr√©ation du contexte audio...');
            audioContextListener = new (window.AudioContext || window.webkitAudioContext)({
                sampleRate: 48000,
                latencyHint: 'interactive'
            });
        }
        
        // Toujours essayer de reprendre le contexte
        if (audioContextListener.state === 'suspended') {
            await audioContextListener.resume();
            console.log('‚úÖ Contexte audio r√©activ√©');
        }
        
        // Cr√©er/connecter gainNode si n√©cessaire
        if (!gainNode) {
            gainNode = audioContextListener.createGain();
            gainNode.gain.value = currentVolume || 1.0;
            gainNode.connect(audioContextListener.destination);
            console.log('‚úÖ GainNode cr√©√© et connect√©');
        }
        
        // D√âTECTER LE FORMAT DU CHUNK
        const chunkFormat = (chunk.format || '').toLowerCase();
        const hasOpusMimeType = chunk.mimeType && (chunk.mimeType.includes('opus') || chunk.mimeType.includes('webm'));
        
        // TRAITER LE CHUNK - PCM16 OU OPUS
        if (chunkFormat === 'pcm16' && chunk.sampleRate) {
            // D√©coder base64
            const binaryString = atob(chunk.data);
            const bytes = new Uint8Array(binaryString.length);
            for (let i = 0; i < binaryString.length; i++) {
                bytes[i] = binaryString.charCodeAt(i);
            }
            
            if (bytes.length % 2 !== 0) {
                console.warn('‚ö†Ô∏è Taille PCM invalide (impair), ignor√©');
                isProcessingBuffer = false;
                if (audioChunksQueue.length > 0 && isPlayingAudio) {
                    processAudioQueue();
                }
                return;
            }
            
                // Convertir en Int16 puis Float32 - QUALIT√â MAXIMALE
                const int16Data = new Int16Array(bytes.buffer);
                const float32Data = new Float32Array(int16Data.length);
                
                // Conversion haute qualit√© avec normalisation
                for (let i = 0; i < int16Data.length; i++) {
                    // Conversion pr√©cise avec normalisation
                    float32Data[i] = Math.max(-1, Math.min(1, int16Data[i] / 32768.0));
                }
                
                // Cr√©er AudioBuffer - QUALIT√â MAXIMALE
                const sampleRate = chunk.sampleRate || 48000; // 48kHz par d√©faut (qualit√© maximale)
                const audioBuffer = audioContextListener.createBuffer(1, float32Data.length, sampleRate);
                audioBuffer.getChannelData(0).set(float32Data);
            
            // Mettre √† jour le volume
            gainNode.gain.value = currentVolume || 1.0;
            
            // Cr√©er et jouer la source
            const source = audioContextListener.createBufferSource();
            source.buffer = audioBuffer;
            source.connect(gainNode);
            
            const duration = audioBuffer.duration;
            
            // Log pour d√©bogage
            if (chunksReceivedCount % 20 === 0) {
                console.log(`üîä Lecture chunk ${chunksReceivedCount}: ${float32Data.length} √©chantillons, ${duration.toFixed(3)}s, volume: ${(currentVolume * 100).toFixed(0)}%, queue: ${audioChunksQueue.length}`);
            }
            
            // G√©rer la fin de lecture
            source.onended = () => {
                isProcessingBuffer = false;
                // Traiter le prochain chunk imm√©diatement
                if (audioChunksQueue.length > 0 && isPlayingAudio) {
                    processAudioQueue();
                }
            };
            
            source.onerror = (e) => {
                console.error('‚ùå Erreur source PCM:', e);
                isProcessingBuffer = false;
                // Continuer avec le prochain chunk
                if (audioChunksQueue.length > 0 && isPlayingAudio) {
                    processAudioQueue();
                }
            };
            
            // D√âMARRER LA LECTURE - PROTECTION ANTI-CRASH
            try {
                source.start(0);
                updateAudioStatus(true, `Lecture: ${chunksReceivedCount} chunks`);
                
                // Planifier le traitement du prochain chunk AVANT la fin (pour continuit√©)
                const nextChunkDelay = Math.max(duration * 1000 - 30, 0); // R√©duit de 50ms √† 30ms pour meilleure continuit√©
                setTimeout(() => {
                    if (!isProcessingBuffer && audioChunksQueue.length > 0 && isPlayingAudio) {
                        processAudioQueue();
                    }
                }, nextChunkDelay);
            } catch (error) {
                console.error('‚ùå Erreur start source:', error);
                isProcessingBuffer = false;
                // Continuer avec le prochain chunk
                if (audioChunksQueue.length > 0 && isPlayingAudio) {
                    setTimeout(() => processAudioQueue(), 50);
                }
            }
            
        } else if (chunkFormat === 'opus' || hasOpusMimeType) {
            // FORMAT OPUS - Utiliser MediaSource API pour cr√©er un stream continu
            const mimeType = chunk.mimeType || 'audio/webm;codecs=opus';
            
            console.log(`üéµ Traitement chunk Opus: format=${chunk.format}, mimeType=${chunk.mimeType}, dataLength=${chunk.data ? chunk.data.length : 0}`);
            
            try {
                // Convertir base64 en ArrayBuffer
                const binaryString = atob(chunk.data);
                const bytes = new Uint8Array(binaryString.length);
                for (let i = 0; i < binaryString.length; i++) {
                    bytes[i] = binaryString.charCodeAt(i);
                }
                
                // SOLUTION SIMPLIFI√âE : Utiliser Web Audio API pour d√©coder Opus
                // Mais comme Web Audio ne d√©code pas Opus directement, on va utiliser une approche diff√©rente
                // On va cr√©er un AudioContext et utiliser decodeAudioData, mais √ßa ne fonctionne pas avec les fragments
                
                // SOLUTION ALTERNATIVE : Forcer l'admin √† envoyer en PCM16
                // Pour l'instant, on va ignorer les chunks Opus et demander √† l'admin d'utiliser PCM16
                console.warn('‚ö†Ô∏è Format Opus d√©tect√© mais non support√© pour la lecture en fragments.');
                console.warn('üí° Solution: Configurez l\'admin pour utiliser PCM16 au lieu d\'Opus.');
                console.warn('   Les chunks Opus WebM ne peuvent pas √™tre jou√©s individuellement.');
                
                // Ignorer ce chunk et continuer
                isProcessingBuffer = false;
                if (audioChunksQueue.length > 0 && isPlayingAudio) {
                    processAudioQueue();
                }
                return;
                
            } catch (error) {
                console.error('‚ùå Erreur traitement Opus:', error);
                isProcessingBuffer = false;
                if (audioChunksQueue.length > 0 && isPlayingAudio) {
                    setTimeout(() => processAudioQueue(), 50);
                }
                return;
            }
        } else {
            console.warn('‚ö†Ô∏è Format non support√©:', chunk.format);
            isProcessingBuffer = false;
            if (audioChunksQueue.length > 0 && isPlayingAudio) {
                processAudioQueue();
            }
        }
        
    } catch (error) {
        console.error('‚ùå Erreur traitement chunk:', error);
        isProcessingBuffer = false;
        updateAudioStatus(false, 'Erreur traitement');
        // Continuer avec le prochain chunk
        if (audioChunksQueue.length > 0 && isPlayingAudio) {
            setTimeout(() => processAudioQueue(), 50);
        }
    }
}

// ============================================
// CONTR√îLE DE VOLUME
// ============================================

const volumeBtn = document.getElementById('volumeBtn');
const volumeSliderContainer = document.getElementById('volumeSliderContainer');
const volumeSlider = document.getElementById('volumeSlider');
const volumeValue = document.getElementById('volumeValue');

// Charger le volume sauvegard√©
const savedVolume = localStorage.getItem('radioVolume');
if (savedVolume !== null) {
    currentVolume = parseFloat(savedVolume);
    if (volumeSlider) volumeSlider.value = currentVolume * 100;
    if (volumeValue) volumeValue.textContent = Math.round(currentVolume * 100) + '%';
}

// Toggle affichage du slider
if (volumeBtn) {
    volumeBtn.addEventListener('click', () => {
        if (volumeSliderContainer) {
            const isVisible = volumeSliderContainer.style.display !== 'none';
            volumeSliderContainer.style.display = isVisible ? 'none' : 'flex';
        }
    });
}

// Changer le volume
if (volumeSlider) {
    volumeSlider.addEventListener('input', (e) => {
        currentVolume = e.target.value / 100;
        
        // Mettre √† jour le gainNode
        if (gainNode) {
            gainNode.gain.value = currentVolume;
        }
        
        // Sauvegarder
        localStorage.setItem('radioVolume', currentVolume);
        
        // Mettre √† jour l'affichage
        if (volumeValue) {
            volumeValue.textContent = Math.round(currentVolume * 100) + '%';
        }
        
        console.log(`üîä Volume: ${Math.round(currentVolume * 100)}%`);
    });
}

// Initialisation
updateTime();
updateTrackTitle();
setInterval(updateTime, 1000); // Mettre √† jour l'heure chaque seconde

// Activer l'audio automatiquement au chargement de la page
// Cela permet au navigateur de d√©tecter que le site veut jouer de l'audio
document.addEventListener('DOMContentLoaded', () => {
    // Cr√©er un contexte audio d√®s le chargement pour "r√©server" les permissions
    try {
        if (!audioContextListener || audioContextListener.state === 'closed') {
            audioContextListener = new (window.AudioContext || window.webkitAudioContext)({
                sampleRate: 48000,
                latencyHint: 'interactive'
            });
            console.log('‚úÖ Contexte audio pr√©-initialis√© pour autoriser la diffusion');
            
            // Essayer de le mettre en √©tat "running" imm√©diatement
            if (audioContextListener.state === 'suspended') {
                audioContextListener.resume().catch(err => {
                    console.log('‚ÑπÔ∏è Contexte audio suspendu, sera activ√© lors de la premi√®re diffusion');
                });
            }
        }
    } catch (error) {
        console.warn('‚ö†Ô∏è Impossible de pr√©-initialiser le contexte audio:', error);
    }
    
    // √âcouter les interactions utilisateur pour d√©bloquer l'audio
    // Fonction am√©lior√©e pour d√©bloquer l'audio (optimis√©e pour mobile)
    const unlockAudio = () => {
        if (isMobile) {
            console.log('üì± D√©blocage audio mobile...');
        }
        if (audioContextListener && audioContextListener.state === 'suspended') {
            audioContextListener.resume().then(() => {
                console.log('‚úÖ Audio d√©bloqu√© par interaction utilisateur');
                // Sur mobile, aussi d√©marrer l'√©coute si une diffusion est en cours
                if (isMobile && !isPlayingAudio) {
                    database.ref(FIREBASE_RADIO_STATUS_PATH).once('value', (snapshot) => {
                        const status = snapshot.val();
                        if (status && status.isLive === true) {
                            console.log('üì± Mobile: D√©marrage automatique apr√®s d√©blocage');
                            autoStartAudio();
                        }
                    });
                }
            }).catch(err => {
                console.warn('‚ö†Ô∏è Impossible de d√©bloquer l\'audio:', err);
            });
        }
    };
    
    // D√©bloquer l'audio au premier clic/touch - OPTIMIS√â POUR MOBILE
    // Sur mobile, privil√©gier les √©v√©nements tactiles
    const events = isMobile 
        ? ['touchstart', 'touchend', 'click', 'pointerdown', 'pointerup'] // Mobile-first
        : ['click', 'touchstart', 'keydown', 'mousedown', 'pointerdown', 'mousemove'];
    
    events.forEach(eventType => {
        document.addEventListener(eventType, unlockAudio, { once: true, passive: true });
    });
    
    // Sur mobile, aussi √©couter sur le bouton play/pause sp√©cifiquement
    if (isMobile && playPauseBtn) {
        playPauseBtn.addEventListener('touchstart', unlockAudio, { once: true, passive: true });
        playPauseBtn.addEventListener('click', unlockAudio, { once: true, passive: true });
    }
});

// Gestion des √©v√©nements audio player
audioPlayer.addEventListener('play', () => {
    isPlaying = true;
    isPlayingAudio = true;
    playIcon.style.display = 'none';
    pauseIcon.style.display = 'block';
    vinylRecord.classList.add('playing');
    updateAudioStatus(true, 'Lecture en cours');
});

audioPlayer.addEventListener('pause', () => {
    isPlaying = false;
    isPlayingAudio = false;
    playIcon.style.display = 'block';
    pauseIcon.style.display = 'none';
    vinylRecord.classList.remove('playing');
});

audioPlayer.addEventListener('error', (e) => {
    console.error('‚ùå Erreur audio player:', e, audioPlayer.error);
    updateAudioStatus(false, 'Erreur de lecture');
});

// Charger le stream radio depuis Firebase
loadRadioStream();

// Gestion du clavier (espace pour play/pause)
document.addEventListener('keydown', (e) => {
    if (e.code === 'Space') {
        e.preventDefault();
        togglePlayPause();
    }
});

// D√©tection de la visibilit√© de la page (pause si onglet inactif)
document.addEventListener('visibilitychange', () => {
    if (document.hidden && isPlaying && audioPlayer.src) {
        // Optionnel: pause automatique quand l'onglet est cach√©
        // togglePlayPause();
    }
});

// ============================================
// CHAT PUBLIC INTEGRATION
// ============================================

const chatMessages = document.getElementById('chatMessages');
const chatStatus = document.getElementById('chatStatus');
const chatLogin = document.getElementById('chatLogin');
const chatInputContainer = document.getElementById('chatInputContainer');
const usernameInput = document.getElementById('usernameInput');
const loginBtn = document.getElementById('loginBtn');
const messageInput = document.getElementById('messageInput');
const sendBtn = document.getElementById('sendBtn');
const onlineCount = document.getElementById('onlineCount');

// Configuration Firebase
const FIREBASE_MESSAGES_PATH = 'publicChat/messages';
const FIREBASE_USERS_PATH = 'publicChat/users';

// Variables globales
let currentUsername = localStorage.getItem('chatUsername') || null;
let userRef = null;
let messagesRef = null;

// Formatage de l'heure pour les messages
function formatMessageTime(date = new Date()) {
    const hours = String(date.getHours()).padStart(2, '0');
    const minutes = String(date.getMinutes()).padStart(2, '0');
    return `${hours}:${minutes}`;
}

// G√©n√©rer un ID unique pour l'utilisateur
function generateUserId() {
    return 'user_' + Date.now() + '_' + Math.random().toString(36).substr(2, 9);
}

// Ajouter un message au chat
function addMessage(author, content, isSystem = false, messageId = null) {
    const messageDiv = document.createElement('div');
    messageDiv.className = `chat-message ${isSystem ? 'system' : ''}`;
    if (messageId) {
        messageDiv.dataset.messageId = messageId;
    }
    
    const time = formatMessageTime();
    const isOwnMessage = !isSystem && author === currentUsername;
    
    messageDiv.innerHTML = `
        <span class="message-time">${time}</span>
        ${!isSystem ? `<div class="message-header"><span class="message-author ${isOwnMessage ? 'own-message' : ''}">${author}</span></div>` : ''}
        <span class="message-content">${content}</span>
    `;
    
    chatMessages.appendChild(messageDiv);
    chatMessages.scrollTop = chatMessages.scrollHeight;
    
    // Limiter √† 100 messages pour les performances
    if (chatMessages.children.length > 100) {
        chatMessages.removeChild(chatMessages.firstChild);
    }
}

// Mettre √† jour le statut de connexion
function updateStatus(connected, text) {
    chatStatus.textContent = text || (connected ? 'Connect√©' : 'D√©connect√©');
    chatStatus.className = `status-text ${connected ? 'connected' : ''}`;
}

// Initialiser le chat
function initChat() {
    // V√©rifier si l'utilisateur a d√©j√† un pseudo
    if (currentUsername) {
        joinChat(currentUsername);
    } else {
        // Afficher le formulaire de connexion
        chatLogin.style.display = 'block';
        chatInputContainer.style.display = 'none';
    }
}

// Rejoindre le chat avec un pseudo
function joinChat(username) {
    if (!username || username.trim() === '') {
        alert('Veuillez entrer un pseudo valide');
        return;
    }
    
    username = username.trim().substring(0, 20);
    currentUsername = username;
    localStorage.setItem('chatUsername', username);
    
    // Masquer le formulaire de connexion
    chatLogin.style.display = 'none';
    chatInputContainer.style.display = 'block';
    
    // Se connecter √† Firebase
    connectToChat();
}

// Se connecter au chat Firebase
function connectToChat() {
    try {
        console.log('üîÑ Connexion au chat public...');
        
        // Enregistrer l'utilisateur comme √©tant en ligne
        const userId = generateUserId();
        userRef = database.ref(`${FIREBASE_USERS_PATH}/${userId}`);
        userRef.set({
            username: currentUsername,
            joinedAt: new Date().toISOString(),
            lastSeen: new Date().toISOString()
        });
        
        // Mettre √† jour lastSeen toutes les 30 secondes
        setInterval(() => {
            if (userRef) {
                userRef.update({ lastSeen: new Date().toISOString() });
            }
        }, 30000);
        
        // Compter les utilisateurs en ligne (ceux qui ont √©t√© actifs dans les 2 derni√®res minutes)
        database.ref(FIREBASE_USERS_PATH).on('value', (snapshot) => {
            const users = snapshot.val();
            if (users) {
                const now = new Date().getTime();
                const onlineUsers = Object.values(users).filter(user => {
                    const lastSeen = new Date(user.lastSeen).getTime();
                    return (now - lastSeen) < 120000; // 2 minutes
                });
                onlineCount.textContent = onlineUsers.length;
            } else {
                onlineCount.textContent = '0';
            }
        });
        
        // Charger les messages existants
        messagesRef = database.ref(FIREBASE_MESSAGES_PATH);
        messagesRef.limitToLast(50).once('value', (snapshot) => {
            const messages = snapshot.val();
            if (messages) {
                // Vider les messages existants (sauf le message syst√®me)
                chatMessages.innerHTML = '';
                
                // Trier par timestamp
                const sortedMessages = Object.entries(messages)
                    .map(([key, msg]) => ({ key, ...msg }))
                    .sort((a, b) => {
                        const timeA = a.timestamp ? new Date(a.timestamp).getTime() : 0;
                        const timeB = b.timestamp ? new Date(b.timestamp).getTime() : 0;
                        return timeA - timeB;
                    });
                
                sortedMessages.forEach(msg => {
                    if (msg.author && msg.content) {
                        addMessage(msg.author, msg.content, false, msg.key || null);
                    }
                });
            }
        });
        
        // √âcouter les nouveaux messages
        messagesRef.limitToLast(50).on('child_added', (snapshot) => {
            const message = snapshot.val();
            if (message && message.author && message.content) {
                const messageId = snapshot.key;
                // V√©rifier si le message n'existe pas d√©j√†
                const existingMessage = chatMessages.querySelector(`[data-message-id="${messageId}"]`);
                if (!existingMessage) {
                    addMessage(message.author, message.content, false, messageId);
                }
            }
        });
        
        // Message de bienvenue
        addMessage('System', `${currentUsername} a rejoint le chat`, true);
        
        console.log('‚úÖ Connect√© au chat public');
        updateStatus(true, 'Connect√©');
        
    } catch (error) {
        console.error('‚ùå Erreur Firebase:', error);
        updateStatus(false, 'Erreur de connexion');
        addMessage('System', 'Erreur de connexion au chat. V√©rifiez la configuration Firebase.', true);
    }
}

// Envoyer un message
function sendMessage() {
    const content = messageInput.value.trim();
    if (!content || !currentUsername) {
        return;
    }
    
    if (content.length === 0) {
        return;
    }
    
    // √âviter les messages vides ou trop longs
    if (content.length > 500) {
        alert('Le message est trop long (max 500 caract√®res)');
        return;
    }
    
    // √âcrire dans Firebase
    const messageRef = database.ref(FIREBASE_MESSAGES_PATH).push();
    messageRef.set({
        author: currentUsername,
        content: content,
        timestamp: new Date().toISOString()
    }).then(() => {
        messageInput.value = '';
        console.log('‚úÖ Message envoy√©');
    }).catch((error) => {
        console.error('‚ùå Erreur envoi message:', error);
        alert('Erreur lors de l\'envoi du message');
    });
}

// √âv√©nements
loginBtn.addEventListener('click', () => {
    joinChat(usernameInput.value);
});

usernameInput.addEventListener('keypress', (e) => {
    if (e.key === 'Enter') {
        joinChat(usernameInput.value);
    }
});

sendBtn.addEventListener('click', sendMessage);

messageInput.addEventListener('keypress', (e) => {
    if (e.key === 'Enter') {
        sendMessage();
    }
});

// Nettoyer √† la fermeture de la page
window.addEventListener('beforeunload', () => {
    if (userRef) {
        userRef.remove();
    }
});

// Initialisation du chat (attendre que Firebase soit pr√™t)
if (typeof firebase !== 'undefined' && firebase.apps.length > 0) {
    initChat();
} else {
    setTimeout(() => {
        if (typeof firebase !== 'undefined' && firebase.apps.length > 0) {
            initChat();
        } else {
            console.error('Firebase non initialis√©');
            updateStatus(false, 'Firebase non configur√©');
        }
    }, 1000);
}

